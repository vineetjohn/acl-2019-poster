%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Jacobs Landscape Poster
% LaTeX Template
% Version 1.0 (29/03/13)
%
% Created by:
% Computational Physics and Biophysics Group, Jacobs University
% https://teamwork.jacobs-university.de:8443/confluence/display/CoPandBiG/LaTeX+Poster
% 
% Further modified by:
% Nathaniel Johnston (nathaniel@njohnston.ca)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[final]{beamer}

\usepackage[scale=1.24]{beamerposter} % Use the beamerposter package for laying out the poster

\usetheme{confposter} % Use the confposter theme supplied with this template

\setbeamercolor{block title}{fg=ngreen,bg=white} % Colors of the block titles
\setbeamercolor{block body}{fg=black,bg=white} % Colors of the body of blocks
\setbeamercolor{block alerted title}{fg=white,bg=dblue!70} % Colors of the highlighted block titles
\setbeamercolor{block alerted body}{fg=black,bg=dblue!10} % Colors of the body of highlighted blocks
% Many more colors are available for use in beamerthemeconfposter.sty

%-----------------------------------------------------------
% Define the column widths and overall poster size
% To set effective sepwid, onecolwid and twocolwid values, first choose how many columns you want and how much separation you want between columns
% In this template, the separation width chosen is 0.024 of the paper width and a 4-column layout
% onecolwid should therefore be (1-(# of columns+1)*sepwid)/# of columns e.g. (1-(4+1)*0.024)/4 = 0.22
% Set twocolwid to be (2*onecolwid)+sepwid = 0.464
% Set threecolwid to be (3*onecolwid)+2*sepwid = 0.708

\newlength{\sepwid}
\newlength{\onecolwid}
\newlength{\twocolwid}
\newlength{\threecolwid}
\setlength{\paperwidth}{48in} % A0 width: 46.8in
\setlength{\paperheight}{36in} % A0 height: 33.1in
\setlength{\sepwid}{0.024\paperwidth} % Separation width (white space) between columns
\setlength{\onecolwid}{0.22\paperwidth} % Width of one column
\setlength{\twocolwid}{0.464\paperwidth} % Width of two columns
\setlength{\threecolwid}{0.708\paperwidth} % Width of three columns
\setlength{\topmargin}{-0.5in} % Reduce the top margin size
%-----------------------------------------------------------

\usepackage{graphicx}  % Required for including images
\usepackage{booktabs} % Top and bottom rules for tables
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{bm}
\usepackage{multirow}
\usepackage{makecell}


% bold x for equations
\newcommand{\rmx}{\mathrm x} 
% used for table headers
\newcommand{\tabh}[1]{\multicolumn{1}{c}{\textbf{#1}}}  
\newcommand{\tabhr}[1]{\multicolumn{1}{c}{\textbf{#1}}}  
% used for the top left cell in a table
\newcommand{\tabc}[2]{\multicolumn{1}{c}{\multirow{#1}{*}{\textbf{#2}}}} 
% used for denoting the loss symbol with a subscript
\newcommand{\loss}[1]{J_{\text{#1}}}
% used for denoting the lambda symbol with a subscript
\newcommand{\hyp}[1]{\lambda_{\text{#1}}}
% used for denoting the theta symbol with a subscript
\newcommand{\nnweight}[1]{\bm{\theta_{\text{#1}}}}
% used for denoting the weight symbol (w) with a subscript
\newcommand{\weight}[1]{W_{\text{#1}}}
% used for denoting the bias symbol (b) with a subscript
\newcommand{\bias}[1]{\bm{b_{\text{#1}}}}

%----------------------------------------------------------------------------------------
%	TITLE SECTION 
%----------------------------------------------------------------------------------------

\title{Disentangled Representation Learning for Non-Parallel Text Style Transfer} % Poster title

\author{Vineet John, Lili Mou, Hareesh Bahuleyan and Olga Vechtomova} % Author(s)

\institute{University of Waterloo} % Institution(s)

%----------------------------------------------------------------------------------------

\begin{document}

\graphicspath{{images/}}

\addtobeamertemplate{block end}{}{\vspace*{2ex}} % White space under blocks
\addtobeamertemplate{block alerted end}{}{\vspace*{2ex}} % White space under highlighted (alert) blocks

\setlength{\belowcaptionskip}{2ex} % White space under figures
\setlength\belowdisplayshortskip{2ex} % White space under equations

\begin{frame}[t] % The whole poster is enclosed in one beamer frame

    \begin{columns}[t] % The whole poster consists of three major columns, the second of which is split into two columns twice - the [t] option aligns each column's content to the top

        \begin{column}{\sepwid}\end{column} % Empty spacer column

        \begin{column}{\onecolwid} % The first column

            %----------------------------------------------------------------------------------------
            %	OBJECTIVES
            %----------------------------------------------------------------------------------------

            \begin{alertblock}{Objectives}

                \begin{itemize}
                    \item Disentangle the latent representations into style and content
                    \item Use the disentangled space to style transfer generation
                \end{itemize}

            \end{alertblock}

            %----------------------------------------------------------------------------------------
            %	INTRODUCTION
            %----------------------------------------------------------------------------------------

            \begin{block}{Introduction}

                \begin{itemize}
                    \item \textbf{Disentangling Latent Space}
                          \begin{itemize}\normalsize
                              \item[] E.g., $\bm h$ = [Sentiment, Subject] (This paper)
                              \item[] E.g., $\bm h$ = [Syntax, Semantics]\\[5pt]

                                    {\setlength{\fboxrule}{3pt}

                                    \fbox{\parbox{\linewidth}{\textbf{Ad: 16:00--17:40 Poster Session 8 \#7}: \small Generating Sentences from Disentangled Syntactic and Semantic Spaces}
                                    }

                                    }
                          \end{itemize}

                          \bigskip
                    \item \textbf{Approach: Auxiliary Losses}
                          \begin{itemize}\normalsize
                              \item[] 1) Adversarial loss for style
                              \item[] 2) Multi-talk loss for style
                              \item[] 3) Adversarial loss for content
                              \item[] 4) Multi-talk loss for content
                          \end{itemize}
                    \item \textbf{Application: Non-parallel text style transfer}

                          \bigskip

                          \begin{itemize}\normalsize
                              \item[] \textbf{Style (esp. sentiment) transfer}:
                                    ``This is very interesting'' $\Rightarrow$`This is very boring''
                              \item[] \textbf{Non-parallel}:  Training data do not have parallel pairs
                          \end{itemize}
                \end{itemize}



            \end{block}

            %------------------------------------------------

            \begin{figure}
                \includegraphics[width=1\linewidth]{model-overview}
                \caption{Model Training and Inference}
                \label{fig:model-overview}
            \end{figure}

            %----------------------------------------------------------------------------------------

        \end{column} % End of the first column

        \begin{column}{\sepwid}\end{column} % Empty spacer column

        \begin{column}{\twocolwid} % Begin a column which is two columns wide (column 2)

            \begin{columns}[t,totalwidth=\twocolwid] % Split up the two columns wide column

                \begin{column}{\onecolwid}\vspace{-.6in} % The first column within column 2 (column 2.1)

                    \begin{block}{Model: Autoencoder \&\\Multi-task Classifier}

                        The \textbf{VAE reconstruction loss} is
                        \begin{align*}
                            \loss{AE}(\nnweight{E}, \nnweight{D}) = & - \mathbb{E}_{q_{E}(\bm h|\rmx)} [\log p(\rmx|\bm h)]    \\
                                                                    & + \hyp{kl}\operatorname{KL}(q_{E}(\bm h|\rmx)\|p(\bm h))
                        \end{align*}
                        where $\hyp{kl}$ is the hyperparameter balancing the reconstruction loss and the KL term. $p(\bm h)$ is the prior, typically the standard normal  $\mathcal{N}(\bm 0,\mathrm I)$. $q_E(\bm h|\mathrm x)$ is the posterior in the form $\mathcal{N}(\bm \mu,\operatorname{diag} \bm\sigma^2)$, where $\bm\mu$ and $\bm\sigma$ are predicted by the encoder.

                        The \textbf{multi-task classifier} loss is given by
                        \begin{equation*}
                            \loss{mul(s)}(\nnweight{E};\nnweight{mul(s)}) = - \sum_{l\in\text{labels}} t_s(l)\log y_s(l)
                        \end{equation*}
                        where $\nnweight{mul(s)}=[\weight{mul(s)}; \bias{mul(s)}]$ are the parameters of the style classifier in the setting of multi-task learning, and $\bm y_s$ is the output of softmax layer.
                        The classifier is trained with cross-entropy loss against the ground-truth distribution.

                    \end{block}

                    %----------------------------------------------------------------------------------------

                \end{column} % End of column 2.1

                \begin{column}{\onecolwid}\vspace{-.6in} % The second column within column 2 (column 2.2)

                    \begin{block}{Model: Discriminator \& Adversary}
                        We train an \textbf{adversarial classifier}, that deliberately discriminates the style/content label. The below equations deal with style information, and are also applied to content in a BoW context.

                        The encoder encodes a content space from which its adversary cannot predict the style.

                        \vspace{-1.6cm}

                        \begin{equation*}
                            \bm y_s                          = \operatorname{softmax}(\weight{dis(s)} \bm c + \bias{dis(s)})
                        \end{equation*}
                        \begin{equation*}
                            \loss{dis(s)}(\nnweight{dis(s)}) = - \sum\nolimits_{l\in\text{labels}} t_c(l)\log y_s(l)
                        \end{equation*}

                        The style-oriented adversarial objective maximizes
                        \begin{equation*}
                            \loss{adv(s)}(\nnweight{E})=\mathcal{H}(\bm y_s|\bm c; \nnweight{dis(s)})
                        \end{equation*}
                        where $\bm y_s$ is the predicted distribution over the style labels/content BoW and $\mathcal{H}(\bm p)=-\sum_{i\in\text{labels}}p_i\log p_i$ is the entropy of the adversary. The objective attains maximum value when $\bm y_s$ is uniform.

                    \end{block}

                    %----------------------------------------------------------------------------------------

                \end{column} % End of column 2.2

            \end{columns} % End of the split of column 2 - any content after this will now take up 2 columns width

            %----------------------------------------------------------------------------------------
            %	IMPORTANT RESULT
            %----------------------------------------------------------------------------------------

            % \begin{alertblock}{Important Result}

            %     We systematically combine multi-task and adversarial objectives to separate content and style from each other, where we also propose to approximate content information with bag-of-words features of style-neutral, non-stopword vocabulary.
            %     The disentangled space can be directly applied to text style-transfer tasks.
            %     Our method achieves high style-transfer strength, high content-preservation scores, as well as high language fluency, compared with previous work.

            % \end{alertblock}

            %----------------------------------------------------------------------------------------

            \begin{columns}[t,totalwidth=\twocolwid] % Split up the two columns wide column again

                \begin{column}{\onecolwid} % The first column within column 2 (column 2.1)

                    \begin{block}{Automated Evaluation}

                        \begin{table}[ht]
                            \centering
                            \begin{tabular}{l c c c c c}
                                \textbf{Model}    & \textbf{STA}     & \textbf{CS}       & \textbf{WO}       & \textbf{PPL}     & \textbf{GM}       \\
                                \hline
                                Fu (2018)         & \color{gray}0.18 & \color{gray} 0.96 & \color{gray} 0.67 & \color{gray} 124 & \color{gray} 0.10 \\
                                Shen (2017)       & \ 0.78           & 0.89              & 0.21              & 93               & 0.12              \\
                                Zhao (2018)       & \ 0.82           & 0.88              & 0.27              & 85               & 0.14              \\
                                Li (2018)         & 0.86             & \textbf{0.94}     & 0.52              & 70               & 0.19              \\
                                Prabhumoye (2018) & 0.85             & 0.83              & 0.08              & 206              & 0.07              \\
                                Xu (2018)         & 0.80             & 0.92              & 0.43              & 470              & 0.09              \\
                                Ours (DAE)        & 0.88             & 0.92              & \textbf{0.55}     & 52               & 0.21              \\
                                Ours (VAE)        & \textbf{0.93}    & 0.90              & 0.47              & \textbf{32}      & \textbf{0.24}     \\
                            \end{tabular}
                            \caption{Performance of text style transfer on the Yelp dataset. \textbf{STA:} Style transfer accuracy. \textbf{CS:} Cosine similarity. \textbf{WO:} Word overlap rate. \textbf{PPL:} Perplexity. \textbf{GM:} Geometric mean.}
                            \label{tab:comparison-previous}
                        \end{table}

                        We observe a clear trade-off between style transfer and content preservation, as they are contradictory goals.

                        Our method consistently achieves the best style-transfer accuracy and perplexity scores, while also maintaining high scores for the content preservation metrics (CS, WO).

                    \end{block}

                    %----------------------------------------------------------------------------------------

                \end{column} % End of column 2.1

                \begin{column}{\onecolwid} % The second column within column 2 (column 2.2)

                    \begin{block}{Human Evaluation}

                        \begin{table}[ht]
                            \centering
                            \begin{tabular}{ l c c c c }
                                \tabc{1}{Model} & \textbf{TS}       & \textbf{CP}       & \textbf{LQ}       & \textbf{GM}       \\
                                \hline
                                Fu (2018)       & \color{gray} 1.67 & \color{gray} 3.84 & \color{gray} 3.66 & \color{gray} 2.86 \\
                                Shen (2017)     & 3.63              & 3.07              & 3.08              & 3.25              \\
                                Zhao (2018)     & 3.55              & 3.09              & 3.77              & 3.46              \\
                                Ours (DAE)      & 3.67              & 3.64              & 4.19              & 3.83              \\
                                Ours (VAE)      & \textbf{4.32}     & \textbf{3.73}     & \textbf{4.48}     & \textbf{4.16}     \\
                            \end{tabular}
                            \caption{Human evaluation on the Yelp dataset with select models.}
                            \label{tab:human-evaluation}
                        \end{table}
                    \end{block}

                    \vspace{-1.6cm}

                    \begin{block}{Latent Space Visualization}
                        \begin{figure}
                            \includegraphics[width=\linewidth]{vae-latent-spaces}
                            \caption{t-SNE plot: Disentangled Latent Spaces generated by VAE on the Yelp Dataset.}
                            \label{fig:tsne-plot}
                        \end{figure}
                    \end{block}

                    %----------------------------------------------------------------------------------------

                \end{column} % End of column 2.2

            \end{columns} % End of the split of column 2

        \end{column} % End of the second column

        \begin{column}{\sepwid}\end{column} % Empty spacer column

        \begin{column}{\onecolwid} % The third column

            %----------------------------------------------------------------------------------------
            %	CONCLUSION
            %----------------------------------------------------------------------------------------

            \begin{block}{Conclusion}

                We systematically combine multi-task and adversarial objectives to separate content and style from each other, where we also propose to approximate content information with bag-of-words features of style-neutral, non-stopword vocabulary.
                The disentangled space can be directly applied to text style-transfer tasks, and achieve high style-transfer, content-preservation and language fluency, compared with previous work.

                For future work, our approach can be naturally extended to non-categorical styles, because our style feature is encoded from the input sentence. Non-categorical styles cannot be easily handled by fixed style embeddings or style-specific decoders.
            \end{block}

            %----------------------------------------------------------------------------------------
            %	ACKNOWLEDGEMENTS
            %----------------------------------------------------------------------------------------

            \setbeamercolor{block title}{fg=red,bg=white} % Change the block title color

            \begin{block}{Acknowledgements}

                \small{\rmfamily{This work was supported in part by the NSERC grant RGPIN-261439-2013 and an Amazon Research Award. We would also like to acknowledge NVIDIA Corporation for the donated Titan Xp GPU.}} \\

            \end{block}

            %----------------------------------------------------------------------------------------
            %	CONTACT INFORMATION
            %----------------------------------------------------------------------------------------

            \setbeamercolor{block alerted title}{fg=black,bg=norange} % Change the alert block title colors
            \setbeamercolor{block alerted body}{fg=black,bg=white} % Change the alert block body colors

            \begin{alertblock}{Contact Information}

                \begin{itemize}
                    \item Web: \href{https://ov-research.uwaterloo.ca/NLP_lab.html}{UWaterloo NLP Lab}
                    \item Email: \href{mailto:ovechtom@uwaterloo.ca}{ovechtom@uwaterloo.ca}
                \end{itemize}

            \end{alertblock}

            \begin{center}
                \begin{tabular}{ccc}
                    \includegraphics[width=0.4\linewidth]{uwaterloo-logo.png}
                \end{tabular}
            \end{center}

            %----------------------------------------------------------------------------------------

        \end{column} % End of the third column

    \end{columns} % End of all the columns in the poster

\end{frame} % End of the enclosing frame

\end{document}
